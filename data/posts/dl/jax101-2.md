---
title: Jax 101-2 🤞
subtitle: Just In Time Compilation with Jax ⏲️
date: 2024-01-27 00:33:00
tags: [dl,jax]
series: 5
cover: /blog/images/jax.jpg
---

> [!abstract] Abstract
>
> 可以看作官方文档[^1]的翻译和简化版


# Just In Time Compilation with Jax ⏲️

## jaxpr

Jax对python函数做微分，首先需要把函数转换成一种名为 `jaxpr` 的简单中间语言，这种语言体现了函数中间的数值运算过程，便于后续的微分操作。[^2]

使用`make_jaxpr`可以生成jaxpr表示

```python
import jax
import jax.numpy as jnp

global_list = []

def log2(x):
  global_list.append(x)
  ln_x = jnp.log(x)
  ln_2 = jnp.log(2.0)
  return ln_x / ln_2

print(jax.make_jaxpr(log2)(3.0))
```

Jax用一种名叫`tracing`的技术生成jaxpr

在`tracing`时，Jax 会用`tracker`来封装每个参数。`tracker`会记录在函数调用期间对它们执行的所有操作。然后，Jax 使用这些记录来重构整个函数。重构的输出就是 jaxpr。



上一节提到，Jax的设计宗旨是写==纯函数==，这一点在jaxpr中也有体现。

因为tracker**不记录副作用**，因此副作用会在`tracing`过程中发生，但是不会出现在jaxpr中

我的理解是，非纯函数的存在会使得原函数和经过jaxpr的编译结果不一致

> [!note] Note
>
> ` print()`函数就是一个非纯函数，会在tracing过程中发生，但是不会出现在jaxpr中



另一个细节是，jaxpr 捕捉的是在给定参数上执行的函数。意思是，它并不记录函数的全部，而是只记录给定参数经过的部分。如对于一个有条件分支的函数，jaxpr只记录当前参数经过的分支。

## jit

`jax.jit`

jit过程发生了什么？

```python
selu_jit = jax.jit(selu)

# Warm up
selu_jit(x).block_until_ready()

%timeit selu_jit(x).block_until_ready()
```

1. `selu` => `selu_jit` 
2. 一旦调用`selu_jit`, Jax用`tracing`把它变成jaxpr，随后，XLA把jaxpr编译成可以在GPU/TPU上高效执行的代码。执行该代码以完成此次调用，随后，对`selu_jit`的调用会直接执行编译后的高效代码，直接绕过python实现

	> Warm up
	> 
	> 这里放warm up是为了排除第一次编译的时间，使得计时更公平

3. 计时 

   > (Note the use of `block_until_ready()`, which is required due to JAX’s [Asynchronous execution](https://jax.readthedocs.io/en/latest/async_dispatch.html) model).

## Why can’t we just JIT everything?

### value conditioned

函数实现依赖参数具体的值的情况下（如x的值参与条件判断），不能jit，因为这样会使得编译后的代码不能重用。

`jax.jit`的默认层次是`ShapedArray`，即，每个`tracker`有确定形状的矩阵，但没有确定的值。

> 所以对矩阵形状做条件判断不会报错

这允许一个jit函数接受相同形状的输入，这符合机器学习的情境。

### with jax.grad

`jax.grad`本身的条件是很宽松的，但是如果和`jax.jit`，如`jax.jit(jax.grad(f))`，就要求`f`中没有依赖参数的值的条件判断。

解决这个问题的方法：

1. 重写代码，避免条件判断

2. 使用特殊的控制方法，如`jax.lax.cond`

3. 只对函数中的一部分jit

4. 用`static_argnums`或`static_argnames`的属性告诉jax其中有固定的参数，此时只要出现不同的参数值，就重新编译该jit函数

   > 仅在有限个参数取值时，才考虑使用，否则会造成很低的效率

   ```python
   f(x, n): 
       pass
   
   g(x, n):
       pass
   
   f_jit_correct = jax.jit(f, static_argnums=0)
   g_jit_correct = jax.jit(g, static_argnames=['n'])
   ```
   
   > [!Note] Note
   >
   > 固定参数还常用`functools.partial`[^3]
   >
   > ```python
   > from functools import partial
   > 
   > @partial(jax.jit, static_argnames=['n'])
   > def g_jit_decorated(x, n):
   >   i = 0
   >   while i < n:
   >     i += 1
   >   return x + i
   > 
   > print(g_jit_decorated(10, 20))
   > ```

##  When to use JIT

`jax.jit`本身会带来一些开销。因此，通常只有当编译的函数很复杂，而且要运行无数次时，`jax.jit` 才会节省时间。幸运的是，这在机器学习中很常见，我们往往会编译一个大型、复杂的模型，然后运行数百万次迭代。 

一般来说，可以将计算中尽可能大的部分（理想情况下是整个更新步骤）jit 出来。这将为编译器提供最大的优化自由度。

## Cache

减少在循环中使用`jax.jit`，等价的不同函数被重新编译时，由于cache的存储依赖哈希值，多次编译会导致冲突，产生不必要的编译

见示例

```python
from functools import partial

def unjitted_loop_body(prev_i):
  return prev_i + 1

def g_inner_jitted_partial(x, n):
  i = 0
  while i < n:
    # Don't do this! each time the partial returns
    # a function with different hash
    i = jax.jit(partial(unjitted_loop_body))(i)
  return x + i

def g_inner_jitted_lambda(x, n):
  i = 0
  while i < n:
    # Don't do this!, lambda will also return
    # a function with a different hash
    i = jax.jit(lambda x: unjitted_loop_body(x))(i)
  return x + i

def g_inner_jitted_normal(x, n):
  i = 0
  while i < n:
    # this is OK, since JAX can find the
    # cached, compiled function
    i = jax.jit(unjitted_loop_body)(i)
  return x + i

print("jit called in a loop with partials:")
%timeit g_inner_jitted_partial(10, 20).block_until_ready()

print("jit called in a loop with lambdas:")
%timeit g_inner_jitted_lambda(10, 20).block_until_ready()

print("jit called in a loop with caching:")
%timeit g_inner_jitted_normal(10, 20).block_until_ready()
```

[^1]: https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html
[^2]: https://zhuanlan.zhihu.com/p/474724292
[^3]: https://zhuanlan.zhihu.com/p/47124891



​                                                                                                                                                                                                                                                                                                                 

